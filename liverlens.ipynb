{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the datasets\n",
    "data1 = pd.read_csv('data1.csv')\n",
    "data2 = pd.read_csv('data2.csv')\n",
    "data3 = pd.read_csv('data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Merge datasets on 'id' where applicable\n",
    "merged_data = pd.merge(data1, data2, on='id', how='inner')\n",
    "merged_data = pd.merge(merged_data, data3, left_on='id', right_on='seqno', how='inner')\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['age_x', 'weight', 'height', 'bmi', 'futime']\n",
    "categorical_features = ['male']\n",
    "\n",
    "# Numerical transformer\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical transformer\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the target variable\n",
    "X = merged_data.drop(columns=['status'])\n",
    "y = merged_data['status']\n",
    "\n",
    "# Apply the preprocessor to the merged data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert target labels to numpy array with float32 dtype\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>id</th>\n",
       "      <th>age_x</th>\n",
       "      <th>male</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bmi</th>\n",
       "      <th>case.id</th>\n",
       "      <th>futime</th>\n",
       "      <th>status</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seqno</th>\n",
       "      <th>instit</th>\n",
       "      <th>histol</th>\n",
       "      <th>stage</th>\n",
       "      <th>study</th>\n",
       "      <th>rel</th>\n",
       "      <th>edrel</th>\n",
       "      <th>age_y</th>\n",
       "      <th>in.subcohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3631</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>22.690939</td>\n",
       "      <td>10630.0</td>\n",
       "      <td>6261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6075</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3631</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>22.690939</td>\n",
       "      <td>10630.0</td>\n",
       "      <td>6261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6075</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3631</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>22.690939</td>\n",
       "      <td>10630.0</td>\n",
       "      <td>6261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6075</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3631</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>22.690939</td>\n",
       "      <td>10630.0</td>\n",
       "      <td>6261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6075</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3631</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>22.690939</td>\n",
       "      <td>10630.0</td>\n",
       "      <td>6261</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6075</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x  id  age_x  male  weight  height        bmi  case.id  futime  \\\n",
       "0          3631   1     57     0    60.0   163.0  22.690939  10630.0    6261   \n",
       "1          3631   1     57     0    60.0   163.0  22.690939  10630.0    6261   \n",
       "2          3631   1     57     0    60.0   163.0  22.690939  10630.0    6261   \n",
       "3          3631   1     57     0    60.0   163.0  22.690939  10630.0    6261   \n",
       "4          3631   1     57     0    60.0   163.0  22.690939  10630.0    6261   \n",
       "\n",
       "   status  ...  Unnamed: 0  seqno instit  histol  stage  study  rel  edrel  \\\n",
       "0       0  ...           1      1      2       2      1      3    0   6075   \n",
       "1       0  ...           1      1      2       2      1      3    0   6075   \n",
       "2       0  ...           1      1      2       2      1      3    0   6075   \n",
       "3       0  ...           1      1      2       2      1      3    0   6075   \n",
       "4       0  ...           1      1      2       2      1      3    0   6075   \n",
       "\n",
       "   age_y  in.subcohort  \n",
       "0     25         False  \n",
       "1     25         False  \n",
       "2     25         False  \n",
       "3     25         False  \n",
       "4     25         False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.initializers import HeNormal, GlorotUniform\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "# Define the model creation function\n",
    "def create_model(optimizer='adam', init='he_normal'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_initializer=init))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer=init))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "576/576 [==============================] - 1s 2ms/step\n",
      "576/576 [==============================] - 1s 1ms/step\n",
      "576/576 [==============================] - 1s 1ms/step\n",
      "576/576 [==============================] - 1s 1ms/step\n",
      "576/576 [==============================] - 1s 944us/step\n",
      "576/576 [==============================] - 1s 1ms/step\n",
      "Best accuracy: 0.9591892185631996\n",
      "Best parameters: {'optimizer': 'Adam', 'init': 'he_normal'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define legacy optimizers\n",
    "optimizers = {\n",
    "    'Adam': legacy.Adam(),\n",
    "    'RMSprop': legacy.RMSprop(),\n",
    "    'SGD': legacy.SGD()\n",
    "}\n",
    "initializers = ['he_normal', 'glorot_uniform']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Manual grid search\n",
    "for opt_name, optimizer in optimizers.items():\n",
    "    for init in initializers:\n",
    "        model = create_model(optimizer, init)\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Keep track of the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = {'optimizer': opt_name, 'init': init}\n",
    "\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/576 [==============================] - 2s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98     16341\n",
      "         1.0       0.96      0.67      0.79      2061\n",
      "\n",
      "    accuracy                           0.96     18402\n",
      "   macro avg       0.96      0.83      0.88     18402\n",
      "weighted avg       0.96      0.96      0.96     18402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build and train the best model\n",
    "best_optimizer = optimizers[best_params['optimizer']]\n",
    "best_init = best_params['init']\n",
    "\n",
    "best_model = create_model(best_optimizer, best_init)\n",
    "best_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (2.15.0)\n",
      "Collecting autokeras\n",
      "  Downloading autokeras-2.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Collecting keras-tuner>=1.4.0 (from autokeras)\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting keras-nlp>=0.8.0 (from autokeras)\n",
      "  Downloading keras_nlp-0.14.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is looking at multiple versions of autokeras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting autokeras\n",
      "  Downloading autokeras-1.1.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from autokeras) (2.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from keras-nlp>=0.8.0->autokeras) (2023.10.3)\n",
      "Collecting rich (from keras-nlp>=0.8.0->autokeras)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting kagglehub (from keras-nlp>=0.8.0->autokeras)\n",
      "  Downloading kagglehub-0.2.9-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Downloading keras_nlp-0.14.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.14.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.14.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.14.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.12.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting dm-tree (from keras-nlp>=0.4.0->autokeras)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting keras-nlp>=0.4.0 (from autokeras)\n",
      "  Downloading keras_nlp-0.12.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.11.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "INFO: pip is still looking at multiple versions of keras-nlp to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading keras_nlp-0.11.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Downloading keras_nlp-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.9.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.9.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.9.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading keras_nlp-0.9.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.8.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.8.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.8.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.7.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "  Downloading keras_nlp-0.6.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading keras_nlp-0.6.3-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading keras_nlp-0.6.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading keras_nlp-0.6.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading keras_nlp-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading keras_nlp-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading keras_nlp-0.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "  Downloading keras_nlp-0.4.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading keras_nlp-0.4.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting autokeras\n",
      "  Downloading autokeras-1.0.20-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from keras-tuner>=1.4.0->autokeras) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner>=1.4.0->autokeras)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->autokeras) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->autokeras) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from pandas->autokeras) (2023.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner>=1.4.0->autokeras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner>=1.4.0->autokeras) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from requests->keras-tuner>=1.4.0->autokeras) (2023.11.17)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sumit\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/162.4 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 30.7/162.4 kB 445.2 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 41.0/162.4 kB 495.5 kB/s eta 0:00:01\n",
      "   ------------------- ------------------- 81.9/162.4 kB 573.4 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 92.2/162.4 kB 525.1 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 122.9/162.4 kB 602.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 153.6/162.4 kB 573.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 162.4/162.4 kB 574.1 kB/s eta 0:00:00\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 20.5/129.1 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 51.2/129.1 kB 871.5 kB/s eta 0:00:01\n",
      "   ------------------------ -------------- 81.9/129.1 kB 919.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 129.1/129.1 kB 951.3 kB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner, autokeras\n",
      "Successfully installed autokeras-1.0.20 keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Attention, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your training and validation datasets\n",
    "train_dir = 'C:/Users/sumit/Desktop/Deep Learning/train'  \n",
    "val_dir = 'C:/Users/sumit/Desktop/Deep Learning/validation'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 141 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Function to load images and labels into NumPy arrays\n",
    "def load_images_from_directory(directory, target_size=(224, 224)):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=target_size,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Extract images and labels\n",
    "    images, labels = [], []\n",
    "    for i in range(len(generator)):\n",
    "        img, lbl = generator[i]\n",
    "        images.append(img)\n",
    "        labels.append(lbl)\n",
    "    \n",
    "    return np.vstack(images), np.vstack(labels)\n",
    "\n",
    "# Load training and validation data\n",
    "X_train, y_train = load_images_from_directory(train_dir)\n",
    "X_val, y_val = load_images_from_directory(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 02m 30s]\n",
      "val_loss: 1.1400482654571533\n",
      "\n",
      "Best val_loss So Far: 0.4665016531944275\n",
      "Total elapsed time: 00h 03m 18s\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 5s 845ms/step - loss: 72.4137 - accuracy: 0.1631 - val_loss: 20.9517 - val_accuracy: 0.3226\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 4s 767ms/step - loss: 6.4027 - accuracy: 0.6596 - val_loss: 5.6383 - val_accuracy: 0.3226\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 4s 819ms/step - loss: 4.2713 - accuracy: 0.2482 - val_loss: 0.4789 - val_accuracy: 0.6774\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 0.7799 - accuracy: 0.6596 - val_loss: 0.5472 - val_accuracy: 0.6774\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 4s 813ms/step - loss: 0.8954 - accuracy: 0.6596 - val_loss: 0.6606 - val_accuracy: 0.6774\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 4s 867ms/step - loss: 0.6271 - accuracy: 0.5674 - val_loss: 0.5075 - val_accuracy: 0.6774\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.5276 - accuracy: 0.6170 - val_loss: 0.4701 - val_accuracy: 0.6774\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 0.5005 - accuracy: 0.6241 - val_loss: 0.4675 - val_accuracy: 0.6774\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 4s 837ms/step - loss: 0.4895 - accuracy: 0.6525 - val_loss: 0.4716 - val_accuracy: 0.6774\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 4s 825ms/step - loss: 0.4915 - accuracy: 0.6241 - val_loss: 0.4813 - val_accuracy: 0.6774\n",
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\image_classifier\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f37b41e650>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "\n",
    "# Initialize the ImageClassifier\n",
    "clf = ak.ImageClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=2  # You can increase this for more thorough searches\n",
    ")\n",
    "\n",
    "# Train the model with NumPy arrays\n",
    "clf.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 [(None, 224, 224, 3)]\n",
      "cast_to_float32 (None, 224, 224, 3)\n",
      "normalization (None, 224, 224, 3)\n",
      "conv2d (None, 222, 222, 32)\n",
      "conv2d_1 (None, 220, 220, 64)\n",
      "max_pooling2d (None, 110, 110, 64)\n",
      "dropout (None, 110, 110, 64)\n",
      "flatten (None, 774400)\n",
      "dropout_1 (None, 774400)\n",
      "dense (None, 3)\n",
      "classification_head_1 (None, 3)\n"
     ]
    }
   ],
   "source": [
    "for layer in best_model.layers:\n",
    "    print(layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 6s 790ms/step - loss: 15.7752 - accuracy: 0.6525 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 4s 822ms/step - loss: 16.0038 - accuracy: 0.6454 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 4s 840ms/step - loss: 15.7752 - accuracy: 0.6454 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 4s 756ms/step - loss: 15.7752 - accuracy: 0.6596 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 4s 756ms/step - loss: 15.7752 - accuracy: 0.6667 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 5s 913ms/step - loss: 15.8895 - accuracy: 0.6596 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 4s 830ms/step - loss: 15.7752 - accuracy: 0.6596 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 4s 775ms/step - loss: 15.7752 - accuracy: 0.6596 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 4s 769ms/step - loss: 15.7752 - accuracy: 0.6667 - val_loss: 16.1181 - val_accuracy: 0.6774\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 4s 796ms/step - loss: 15.8895 - accuracy: 0.6525 - val_loss: 16.1181 - val_accuracy: 0.6774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f29460c610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Multiply, Activation, BatchNormalization, Flatten\n",
    "\n",
    "# Get the input shape from the best model\n",
    "input_shape = best_model.input_shape[1:]\n",
    "\n",
    "# Rebuild the model with added attention layers\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Use the existing layers from the best model up to the last convolutional layer\n",
    "x = inputs\n",
    "for layer in best_model.layers[1:]:\n",
    "    if isinstance(layer, Flatten):  # Stop before the Flatten layer\n",
    "        break\n",
    "    x = layer(x)\n",
    "\n",
    "# At this point, x should have shape (None, 110, 110, 64)\n",
    "\n",
    "# Spatial Attention mechanism\n",
    "# 1. Apply a 1x1 convolution to generate an attention map\n",
    "attn = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "# 2. Multiply the attention map with the input feature map\n",
    "x = Multiply()([x, attn])\n",
    "\n",
    "# Now flatten the output\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Continue with the remaining layers from the best model\n",
    "for layer in best_model.layers:\n",
    "    if isinstance(layer, Dense):\n",
    "        x = layer(x)\n",
    "\n",
    "# Rebuild the model\n",
    "model_with_attention = Model(inputs, x)\n",
    "\n",
    "# Compile the enhanced model\n",
    "model_with_attention.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the enhanced model\n",
    "model_with_attention.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step - loss: 16.1181 - accuracy: 0.6774\n",
      "Validation Accuracy with Attention: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation data\n",
    "loss, accuracy = model_with_attention.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy with Attention: {accuracy:.4f}\")\n",
    "\n",
    "# Save the enhanced model\n",
    "model_with_attention.save('fatty_liver_ultrasound_model_with_attention.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
